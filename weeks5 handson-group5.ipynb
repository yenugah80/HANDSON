{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Preparation:\n",
    "Load a healthcare-related dataset (e.g., predicting the likelihood of a patient developing heart disease based on health indicators such as age, blood pressure, cholesterol, etc.).\n",
    "Split the data into training (80%) and test (20%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0   1            6      148             72             35        0  33.6   \n",
      "1   2            1       85             66             29        0  26.6   \n",
      "2   3            8      183             64              0        0  23.3   \n",
      "3   4            1       89             66             23       94  28.1   \n",
      "4   5            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path = r'C:\\Users\\harik\\OneDrive\\Documents\\NWU DOCS\\ML\\kritik\\week 5\\diabetes\\Healthcare-Diabetes.csv'\n",
    "\n",
    "# Load the dataset\n",
    "diabetes_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first 5 rows of the dataset to verify loading\n",
    "print(diabetes_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "Id                          0\n",
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n",
      "Shape of X_train: (2214, 8)\n",
      "Shape of X_test: (554, 8)\n",
      "Shape of y_train: (2214,)\n",
      "Shape of y_test: (554,)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Step 4: Define features (X) and target (y)\n",
    "X = data[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
    "y = data['Outcome']\n",
    "\n",
    "# Step 5: Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Print the shapes of the training and testing sets\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Support Vector Machine (SVM) Results ---\n",
      "Accuracy: 0.7689530685920578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       367\n",
      "           1       0.71      0.53      0.61       187\n",
      "\n",
      "    accuracy                           0.77       554\n",
      "   macro avg       0.75      0.71      0.72       554\n",
      "weighted avg       0.76      0.77      0.76       554\n",
      "\n",
      "\n",
      "--- Gradient Boosting Machine (GBM) Results ---\n",
      "Accuracy: 0.8808664259927798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       367\n",
      "           1       0.87      0.76      0.81       187\n",
      "\n",
      "    accuracy                           0.88       554\n",
      "   macro avg       0.88      0.85      0.86       554\n",
      "weighted avg       0.88      0.88      0.88       554\n",
      "\n",
      "\n",
      "--- Random Forest Classifier Results ---\n",
      "Accuracy: 0.98014440433213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       367\n",
      "           1       0.98      0.96      0.97       187\n",
      "\n",
      "    accuracy                           0.98       554\n",
      "   macro avg       0.98      0.98      0.98       554\n",
      "weighted avg       0.98      0.98      0.98       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/harik/OneDrive/Documents/NWU DOCS/ML/kritik/week 5/diabetes/Healthcare-Diabetes.csv\")\n",
    "\n",
    "# Step 3: Define features (X) and target (y)\n",
    "X = data[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', \n",
    "          'DiabetesPedigreeFunction', 'Age']]  # Features\n",
    "y = data['Outcome']  # Target variable\n",
    "\n",
    "# Step 4: Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Implement and train Support Vector Machine (SVM)\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Implement and train Gradient Boosting Machine (GBM)\n",
    "gbm_model = GradientBoostingClassifier()\n",
    "gbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Implement and train Random Forest Classifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Predict on the test set using all three models\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "gbm_predictions = gbm_model.predict(X_test)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Step 9: Evaluate the models using accuracy score and classification report\n",
    "print(\"\\n--- Support Vector Machine (SVM) Results ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, svm_predictions)}\")\n",
    "print(classification_report(y_test, svm_predictions))\n",
    "\n",
    "print(\"\\n--- Gradient Boosting Machine (GBM) Results ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, gbm_predictions)}\")\n",
    "print(classification_report(y_test, gbm_predictions))\n",
    "\n",
    "print(\"\\n--- Random Forest Classifier Results ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, rf_predictions)}\")\n",
    "print(classification_report(y_test, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning:\n",
    "Use GridSearchCV or RandomizedSearchCV to tune hyperparameters for each of the models (e.g., SVM's kernel, Random Forest's n_estimators, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here i modified few of the n values  for fast run time changes which allows the code to run quickly \n",
    "\n",
    "Smaller Hyperparameter Grids: Reduced the number of options in each hyperparameter grid.\n",
    "Reduced n_iter: Set n_iter=5 in RandomizedSearchCV to limit the number of random samples, which speeds up the tuning process.\n",
    "Reduced Cross-Validation Folds: Set cv=3 for fewer cross-validation folds to decrease computational load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "\n",
      "--- Best Parameters for SVM ---\n",
      "{'kernel': 'linear', 'gamma': 'scale', 'C': 1}\n",
      "SVM Accuracy after tuning: 0.7635379061371841\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.83       367\n",
      "           1       0.70      0.52      0.60       187\n",
      "\n",
      "    accuracy                           0.76       554\n",
      "   macro avg       0.74      0.70      0.72       554\n",
      "weighted avg       0.76      0.76      0.75       554\n",
      "\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Parameters for GBM ---\n",
      "{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}\n",
      "GBM Accuracy after tuning: 0.9819494584837545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       367\n",
      "           1       0.98      0.96      0.97       187\n",
      "\n",
      "    accuracy                           0.98       554\n",
      "   macro avg       0.98      0.98      0.98       554\n",
      "weighted avg       0.98      0.98      0.98       554\n",
      "\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "\n",
      "--- Best Parameters for Random Forest ---\n",
      "{'n_estimators': 200, 'min_samples_split': 2, 'max_depth': None}\n",
      "Random Forest Accuracy after tuning: 0.9819494584837545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       367\n",
      "           1       0.98      0.96      0.97       187\n",
      "\n",
      "    accuracy                           0.98       554\n",
      "   macro avg       0.98      0.98      0.98       554\n",
      "weighted avg       0.98      0.98      0.98       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Define smaller hyperparameter grids for tuning\n",
    "# SVM Hyperparameters\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "# Gradient Boosting Hyperparameters\n",
    "gbm_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "# Random Forest Hyperparameters\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Step 11: Randomized Search for Support Vector Machine (SVM)\n",
    "svm_random = RandomizedSearchCV(SVC(), svm_param_grid, n_iter=5, refit=True, verbose=1, cv=3, n_jobs=-1)\n",
    "svm_random.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation for SVM\n",
    "print(\"\\n--- Best Parameters for SVM ---\")\n",
    "print(svm_random.best_params_)\n",
    "svm_best_predictions = svm_random.predict(X_test)\n",
    "print(f\"SVM Accuracy after tuning: {accuracy_score(y_test, svm_best_predictions)}\")\n",
    "print(classification_report(y_test, svm_best_predictions))\n",
    "\n",
    "# Step 12: Randomized Search for Gradient Boosting Machine (GBM)\n",
    "gbm_random = RandomizedSearchCV(GradientBoostingClassifier(), gbm_param_grid, n_iter=5, refit=True, verbose=1, cv=3, n_jobs=-1)\n",
    "gbm_random.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation for GBM\n",
    "print(\"\\n--- Best Parameters for GBM ---\")\n",
    "print(gbm_random.best_params_)\n",
    "gbm_best_predictions = gbm_random.predict(X_test)\n",
    "print(f\"GBM Accuracy after tuning: {accuracy_score(y_test, gbm_best_predictions)}\")\n",
    "print(classification_report(y_test, gbm_best_predictions))\n",
    "\n",
    "# Step 13: Randomized Search for Random Forest Classifier\n",
    "rf_random = RandomizedSearchCV(RandomForestClassifier(), rf_param_grid, n_iter=5, refit=True, verbose=1, cv=3, n_jobs=-1)\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation for Random Forest\n",
    "print(\"\\n--- Best Parameters for Random Forest ---\")\n",
    "print(rf_random.best_params_)\n",
    "rf_best_predictions = rf_random.predict(X_test)\n",
    "print(f\"Random Forest Accuracy after tuning: {accuracy_score(y_test, rf_best_predictions)}\")\n",
    "print(classification_report(y_test, rf_best_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation:\n",
    "Evaluate each model using the following metrics:\n",
    "Accuracy\n",
    "Precision, Recall, F1-score\n",
    "AUC-ROC\n",
    "Compare the performance of the models on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomizedSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 1: Evaluate SVM\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m svm_best_predictions \u001b[38;5;241m=\u001b[39m \u001b[43msvm_random\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m svm_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, svm_random\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- SVM Evaluation ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\harik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:546\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;129m@available_if\u001b[39m(_estimator_has(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    529\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \n\u001b[0;32m    531\u001b[0m \u001b[38;5;124;03m    Only available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;124;03m        the best found parameters.\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 546\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32mc:\\Users\\harik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1632\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1629\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1632\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This RandomizedSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Evaluate SVM\n",
    "svm_best_predictions = svm_random.predict(X_test)\n",
    "svm_auc = roc_auc_score(y_test, svm_random.predict_proba(X_test)[:, 1])\n",
    "print(\"\\n--- SVM Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, svm_best_predictions)}\")\n",
    "print(f\"Precision: {precision_score(y_test, svm_best_predictions)}\")\n",
    "print(f\"Recall: {recall_score(y_test, svm_best_predictions)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, svm_best_predictions)}\")\n",
    "print(f\"AUC-ROC: {svm_auc}\")\n",
    "\n",
    "# Step 2: Evaluate GBM\n",
    "gbm_best_predictions = gbm_random.predict(X_test)\n",
    "gbm_auc = roc_auc_score(y_test, gbm_random.predict_proba(X_test)[:, 1])\n",
    "print(\"\\n--- GBM Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, gbm_best_predictions)}\")\n",
    "print(f\"Precision: {precision_score(y_test, gbm_best_predictions)}\")\n",
    "print(f\"Recall: {recall_score(y_test, gbm_best_predictions)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, gbm_best_predictions)}\")\n",
    "print(f\"AUC-ROC: {gbm_auc}\")\n",
    "\n",
    "# Step 3: Evaluate Random Forest\n",
    "rf_best_predictions = rf_random.predict(X_test)\n",
    "rf_auc = roc_auc_score(y_test, rf_random.predict_proba(X_test)[:, 1])\n",
    "print(\"\\n--- Random Forest Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, rf_best_predictions)}\")\n",
    "print(f\"Precision: {precision_score(y_test, rf_best_predictions)}\")\n",
    "print(f\"Recall: {recall_score(y_test, rf_best_predictions)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, rf_best_predictions)}\")\n",
    "print(f\"AUC-ROC: {rf_auc}\")\n",
    "\n",
    "# Step 4: Plot ROC Curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# SVM ROC Curve\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test, svm_random.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr_svm, tpr_svm, label=f'SVM (AUC = {svm_auc:.2f})')\n",
    "\n",
    "# GBM ROC Curve\n",
    "fpr_gbm, tpr_gbm, _ = roc_curve(y_test, gbm_random.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr_gbm, tpr_gbm, label=f'GBM (AUC = {gbm_auc:.2f})')\n",
    "\n",
    "# Random Forest ROC Curve\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_random.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {rf_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_random = RandomizedSearchCV(SVC(probability=True), svm_param_grid, n_iter=5, refit=True, verbose=1, cv=3, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Randomized Search for Support Vector Machine (SVM)\n",
    "svm_random = RandomizedSearchCV(SVC(probability=True), svm_param_grid, n_iter=5, refit=True, verbose=1, cv=3, n_jobs=-1)\n",
    "svm_random.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation for SVM\n",
    "print(\"\\n--- Best Parameters for SVM ---\")\n",
    "print(svm_random.best_params_)\n",
    "svm_best_predictions = svm_random.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "evaluate_model(y_test, svm_best_predictions, \"SVM\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
